---
title: "<b>Week 7: Effects coding </b>"
subtitle: "RMS2<br><br> "
author: "TOM BOOTH & ALEX DOUMAS"
institute: "Department of Psychology<br>The University of Edinburgh"
date: "AY 2020-2021"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
   base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
```


# Topics for today

+ Last time we looked at the $F$-test in one-way ANOVA and linear models

+ This time we are going to consider contrasts and $\beta$ coefficients

---
# Looking beneath the F-test
+ The $F$-test gives us an overall test of the model, or the effect of an experimental condition.

+ But we may want to know something more specific.
  + Differences between specific groups or sets of groups.

+ In ANOVA we talk about...
  + contrasts & planned comparisons
  + post-hoc test

+ So how do we approach these from the linear model perspective?

---
# Contrasts and Planned comparisons
+ Sometimes we want to make comparisons between pairs of things.
  + Treatment A vs Treatment B
  + Treatment A vs (Treatment B & Treatment C) etc.

+ This can be done...
  + For a set of specific comparisons (confirmatory)
  + For all possible comparisons (exploratory)
  
+ We achieve this via assigning weights to groups.

+ May sound complicated, but we have already seen this in action this year
  
---
# Dummy coding
+ Also called reference group coding

+ Create $k$-1 dummy variables/contrasts
  + where $k$ is the number of levels of the categorical predictor

+ Assign reference group 0 on all dummies.

+ Assign 1 to the focal group.

+ Enter the dummies into the linear model and they code the difference in means between the focal group/level and the reference.

+ We are going to use $g$ from here on to be explicit these are experimental groups.
  + But if we think in terms of the categorical variables produced by a design $g = k$

---
# Why do we need a reference group?
+ Consider our example.

+ We have three groups each given a specific Treatment A, B or C

+ We want a model that represents our data (observations), but all we "know" are groups. So;

$$y_{ij} = \mu_i + \epsilon_{ij}$$

+ Where 
  + $y_{ij}$ are the individual observations
  + $\mu_i$ is the mean of group $i$ and
  + $\epsilon_{ij}$ is the individual deviation from that mean.


???
+ And this hopefully makes sense.
  + Given we know someone's group, our best guess is the mean
  + But people wont all score the mean, so there is some deviation for every person.


---
# Why do we need a reference group?
+ An alternative way to present this looks much more like our linear model:

$$y_{ij} = \beta_0 + \underbrace{(\mu_{i} - \beta_0)}_{\beta_i} + \epsilon_{ij}$$
+ Where 
  + $y_{ij}$ are the individual observations
  + $\beta_0$ is an estimate of reference/overall average
  + $\mu_i$ is the mean of group $i$ 
  + $\beta_1$ is the difference between the reference and the mean of group $i$, and
  + $\epsilon_{ij}$ is the individual deviation from that mean.

---
# Why do we need a reference group?
+ We can take expectations and write this both generally:

$$\mu_i = \beta_0 + \beta_i $$

+ or for the specific groups (in our case 3):

$$\mu_{treatmentA} = \beta_0 + \beta_{1A}$$

$$\mu_{treatmentB} = \beta_0 + \beta_{2B}$$

$$\mu_{treatmentC} = \beta_0 + \beta_{3C}$$

+ **The problem**: we have four parameters ( $\beta_0$ , $\beta_{1A}$ , $\beta_{2B}$ , $\beta_{3C}$ ) to model three group means ( $\mu_{TreatmentA}$ , $\mu_{TreatmentB}$ , $\mu_{TreatmentC}$ )
  + This means our model is under-identified.
  + We are trying to estimate too much with too little.

---
# Constraints fix identification
+ Consider dummy coding.

+ Suppose we make Treatment A the reference. Then

$$\mu_{treatmentA} = \beta_0$$

$$\mu_{treatmentB} = \beta_0 + \beta_{2B}$$

$$\mu_{treatmentC} = \beta_0 + \beta_{3C}$$
+ Fixed! 

+ We now only have three parameters ( $\beta_0$ , $\beta_{2B}$ , $\beta_{3C}$ ) for the three group means ( $\mu_{TreatmentA}$ , $\mu_{TreatmentB}$ , $\mu_{TreatmentC}$ )

---
# Why not always use dummy coding?

+ We might not always want to compare against a reference group.

+ Consider ANOVA sums of squares calculations.
  + What do we compare the group means to?

--

+ I hope you all shouted "the grand mean"!

+ And there is a form of constraint that allows us to do this.

---
# Sum to zero constraint

+ Instead of the reference constraint 

$$\mu_{reference} = \beta_0$$ 

+ we can apply what is referred to as the sum to zero constraint (again using example of three levels).

$$\beta_1 + \beta_2 + \beta_3 = 0$$

+ There are two consequences of this constraint (see practical exercises for full explanation):

$$\beta_0 = \frac{\mu_1 + \mu_2 + \mu_3}{3}$$

+ And

$$\mu_1 = \beta_0 + \beta_1$$

$$\mu_2 = \beta_0 + \beta_2$$

$$\mu_3 = \beta_0 - (\beta_1 + \beta_2)$$

---
# OK, but how do we apply the constraint?

+ Answer, in the same way as we did with dummy coding.

+ We can create a set of sum to zero (sometimes called effect, or deviation) variables
  + Or the equivalent contrast matrix.
  
+ For effect code variables we:
  + Create $g-1$ variables
  + For observations in the focal group, assign 1
  + For observations in the last group, assign -1
  + For all other groups assign 0


---
# Comparing coding matrices

.pull-left[
```{r echo = FALSE}
tibble(
  Level = c("Treatment A", "Treatment B", "Treatment C"),
  D1 = c(0,1,0),
  D2 = c(0,0,1)
) %>%
  kable(.)%>%
  kable_styling(., full_width = F)
```

$$y_{ij} = \beta_0 + \beta_1D_1 + \beta_2D_2 + \epsilon_{ij}$$

]


.pull-right[

```{r echo = FALSE}
tibble(
  Level = c("Treatment A", "Treatment B", "Treatment C"),
  E1 = c(1,0,-1),
  E2 = c(0,1,-1)
) %>%
  kable(.)%>%
  kable_styling(., full_width = F)
```

$$y_{ij} = \beta_0 + \beta_1E_1 + \beta_2E_2 + \epsilon_{ij}$$

]

---
# Sum to zero/effects for group means

```{r echo = FALSE}
tibble(
  Level = c("Treatment A", "Treatment B", "Treatment C"),
  E1 = c(1,0,-1),
  E2 = c(0,1,-1)
) %>%
  kable(.)%>%
  kable_styling(., full_width = F)
```


$$\mu_1 = \beta_0 + 1*\beta_1 + 0*\beta_2 = \beta_0 + \beta_1$$

$$\mu_2 = \beta_0 + 0*\beta_1 + 1*\beta_2 = \beta_0 + \beta_2$$

$$\mu_3 = \beta_0 -1*\beta_1 -1*\beta_2 = \beta_0 - \beta_1 -\beta_2$$

---
# The wide world of contrasts 
+ We have now seen two examples of coding schemes (dummy and effect).

+ We have also seen that so long as we apply some set of constraints, we are able to do different things.

+ This means there are **lots** of different coding's we can use for categorical variables to make different comparisons.
  + If you are interested, see the excellent resource on [UCLA website](https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/)

+ These can include some custom contrasts (planned comparisons).

---
# Summary of today

+ We have considered different ways in which we can code categorical predictors, such that the group comparisons are equivalent to ANOVA.

+ Take home:
  + Use of coding matrices allows us to compare groups (or levels) in lots of ways
  + We will come to see this is very useful for testing specific hypotheses.
  + Effects (sum to zero, or deviation) coding = traditional ANOVA
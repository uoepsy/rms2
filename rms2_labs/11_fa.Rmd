---
title: "Factor analysis"
bibliography: references.bib
biblio-style: apalike
link-citations: yes
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---


```{r setup, include=FALSE}
source('assets/setup.R')
```

```{r echo=FALSE}
set.seed(3)
```



# Exercises

This is a quick demonstration of one way of dealing with these tasks. It is by no means the only correct way. There is a substantial level of subjectivity in _Exploratory Factor Analysis_ and the method involves repeated evaluation and re-evaluation of the model in light of the extracted factors and their conceptual relationships with the analysed items. In other words, a good EFA requires you to get your hands dirty.

First, let’s read in the data. I would strongly encourage you not to "import" data into RStudio by clicking on menus but rather use code. This way, your script will contain a complete account of the analysis which is invaluable for situations when you return to your data after a long break from the analysis (this will happen!).

In today's lab we will be using the [work pressures survey (WPS) data](https://uoepsy.github.io/data/WPS_data.csv) available at the following link:
https://uoepsy.github.io/data/WPS_data.csv
The data contains responses from 946 workers from a variety of companies to the Work Pressures Survey. Your task in this week's exercises is to perform a factor analysis of the main section of this survey (Job1 to Job50).

You can look at the survey taken by the study participants at the following [link](https://uoepsy.github.io/data/WPS_data_codebook.pdf)

`r qbegin(1)`
Read the WPS data into R. Make sure to take a look at the variable names and data structure.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
library(tidyverse)

df <- read.csv("https://uoepsy.github.io/data/WPS_data.csv")
head(df)
```

Variable names - Option 1:
```{r}
names(df)
```

Variable names - Option 2:
```{r eval=FALSE}
colnames(df)
```

Data structure - Option 1:
```{r}
str(df)
```

Data structure - Option 2:
```{r}
glimpse(df)
```
`r solend()`



`r qbegin(2)`
Produce a table of summary statistics for the variables in the data.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
df %>%
    summarise(across(everything(), 
                     list(M = mean, SD = sd, MIN = min, MAX = max))) %>%
    pivot_longer(everything())
```

We can see that there are a few missing values in some variables.
`r solend()`


`r qbegin(3)`
If you were to analyse this data for a research project hopefully leading to a paper, you would probably want to perform sanity check on the variables, such as check if everyone is an adult (assuming this was a requirement for partaking of the study).

Check whether all participants in the study are adults.

_Hints:_

- The `unique()` function will give us all the unique values in a variable

- What could the variable `doby` represent?
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
unique(df$doby)
```
`r solend()`





`r qbegin(4)`
The data look like a bit of a mess.. Some participants have the full year of birth, some only the last 2 digits. Let’s only extract the last 2 digits from all rows then.

- Look at the help of the `str_sub()` function.

- Use the `str_sub()` function to take only the last 2 characters.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
df <- df %>%
    mutate(doby = str_sub(doby, -2, -1))
```

It seems like it's now a character rather than a number:
```{r}
class(df$doby)
```

Let's make it a number again:
```{r}
df$doby <- as.numeric(df$doby)
```

`r solend()`


`r qbegin(5)`
Visualise the distribution of birth year.

Do you notice anything strange? If yes, how can you solve this?
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Quick histogram:
```{r}
ggplot(df, aes(x = doby)) + 
    geom_histogram(color = 'white')
```

Or a dotplot if you prefer:
```{r}
ggplot(df, aes(x = doby)) + 
    geom_dotplot(dotsize = 0.6, binwidth = 1, fill = 'dodgerblue', color = NA)
```

A year of birth equal to −1 doesn't make any sense and, since we only want to keep adults, we will remove the rows in the data set having a year of birth equal to -1.

In the meantime, we will also remove those participants who don't have a value for `doby`.


```{r}
df <- df %>%
    filter(!is.na(doby) | doby > 0)

hist(df$doby)
```

That looks much better!
`r solend()`



Normally, you'd want to check other variables too.

For now, because we are focusing on EFA, we'll just assume that the other variables are okay.


`r qbegin(6)`
__Subset to relevant data__

Remember that the only variables we are interested in for our EFA are the `job1` to `job50` variables. Subset the data set to only include those variables.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
df <- df %>%
    select(job1:job50)
```

`r solend()`



`r qbegin(7)`
Create a table of descriptive summary statistics for each variable.

This time try using the function `describe()` from the `psych` package.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
library(psych)

describe(df)
```

`r solend()`


`r qbegin(8)`
Some of the variables appear to have values of 0, −1, as well as values larger than 7, even though all the questionnaire items are on a 7-point Likert scale. 

Get rid of infeasible values.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
df[df < 1 | df > 7] <- NA
```

`r solend()`


`r qbegin(9)`
Let's now look at the score distributions per item and the correlations between pairs of items.

- Look at the help for the `pairs.panels()` function from the `psych` package

- Use the `pairs.panels()` function to produce the plots

- __IMPORTANT:__ Do not put too many plots into one figure!
  
  Use subsets of ten variables each time. For example, look at the pairwise plots of the first 10 variables, then the next 10, and so on.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
pairs.panels(df[, 1:10])
pairs.panels(df[, 11:20])
pairs.panels(df[, 21:30])
pairs.panels(df[, 31:40])
pairs.panels(df[, 41:50])
```


`r solend()`

As you can see, while some of the items have pretty much bell-shaped distributions, some others are massively skewed (looking at you `job49`) or close to uniform (`job9`). 
At this stage, you'd want to have a closer look at the wording of these troublesome items and see if you can spot any methodological issues that might account for these distributions. 
If the items look fine, you might want to consider alternative correlation coefficients (e.g., polychoric correlations) that might be more suitable to items with weird distributions. 
For now, let’s stick to Pearson's correlation (r). Since we have NAs in the data, let's just use complete observations.

`r qbegin(10)`
Compute the correlation matrix of the variables.

Instead of looking at the $50 \times 50$ matrix of correlations, look at the distribution of correlation coefficients from the lower triangular part of the matrix.

_Hint: The function `lower.tri(R)` returns the lower triangular part of a matrix, i.e. the numbers below the diagonal._
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
Option 1:
```{r}
R <- cor(df, use = "complete.obs")
```

Option 2:
```{r}
R <- cor(na.omit(df))
```

```{r}
hist(R[lower.tri(R)])
```

`r solend()`


If you want to be a little fancier, you can categorise the coefficients into negligible, weak, moderate, and strong correlations and plot a bar plot like this:

```{r}
Rc <- cut(abs(R), 
          breaks = c(0, .2, .5, .7, 1), 
          labels = c("negligible", "weak", "moderate", "strong"))

barplot(table(Rc[lower.tri(Rc)]))
```


`r qbegin(11)`
As we can see, most of the correlations are negligible and many are weak. There are some moderate and strong relationships in the data. This suggests that there might be multiple independent factors.

Check if the correlations are sufficient for EFA with Bartlett's test of sphericity and if the sample was adequate with KMO.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
cortest.bartlett(R, 
                 n = sum(complete.cases(df))) # we have 917 complete cases
```


```{r}
KMO(R)
```


`r solend()`



A significant Bartlett's test of sphericity means that our correlation matrix is _not_ proportional to an identity matrix (a matrix with only 1s on the diagonal and 0s everywhere else). This is exactly what we want, so we're happy!

Likewise, the sampling adequacy is pretty good. All items have a measure of sampling adequacy (MSA) in the $>.7$ "middling" region and the overall KMO is bordering on the $>.9$ "marvellous" level (I kid you not).

Given these results, we can merrily factor-analyse!


`r qbegin(12)`
In order to decide how many factors to use, look at the suggestions given by parallel analysis and MAP.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
fa.parallel(df, fa = 'fa')
```

```{r}
VSS(df)
```


Since parallel analysis (suggesting 11 factor) tends to overextract and MAP (suggesting 6-8 factors) can sometimes underextract, it is reasonable to look at solutions with 7-10 factors.
However, looking at the scree plot, it might be reasonable to cast a glance on a 5- or 6-factor solution.

`r solend()`


`r qbegin(13)`
Fit a factor analysis model to the data using 10 factors.

Since there is no good reason to expect the factors to be uncorrelated (orthogonal), use the oblimin rotation.  

Before doing so, make sure you have installed the `GPArotation` package
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
m_10f <- fa(df, nfactors = 10, rotate = "oblimin", fm = "ml")
```

Print loadings sorted according to loadings
```{r}
fa.sort(m_10f)
```
`r solend()`



`r qbegin(14)`
OK, 10 factors looks like way too many as the last 2 have very few substantive loadings (>.33). Let’s look at a smaller solution, e.g. 9 or 8 factors and see if it’s still the case...
```
install.packages('GPArotation')
```
`r qend()`
`r solbegin(show=TRUE, toggle=params$TOGGLE)`
```{r}
m_9f <- fa(df, nfactors = 9, rotate = "oblimin", fm = "ml")
m_8f <- fa(df, nfactors = 8, rotate = "oblimin", fm = "ml")
```

It was the case and even the 9-factor solution has only 1 substantive loading on the last factor. These are however quite large so let’s look at this solution a little closer. We can see that a few items don’t have any loadings larger than our .33 cut-off:
We can see that a few items don’t have any loadings larger than our .33 cut-off:

```{r}
# get loadings
x <- m_9f$loadings
which(rowSums(x < .33) == 9)
```

It was the case and even the 8-factor solution has only 2 substantive loadings on the last factor. These are however quite large so let’s look at this solution a little closer. We can see that a few items don’t have any loadings larger than our .33 cut-off:

```{r}
# get loadings
x <- m_8f$loadings
which(rowSums(x < .33) == 8)
```

`r solend()`

Here is when we would go back to the item wordings and try to see why these items might not really correlate with any other items. For instance, `job11` ("I regularly discuss problems at work with my colleagues.") might be ambiguous: does it mean that there are often problems or that if there are problems, I discuss them regularly?

For argument's sake, let's say, all of these identified items are deemed problematic so we should remove them:

```{r}
cols_to_remove <- names(which(rowSums(x < .33) == 8))
df2 <- df[ , !names(df) %in% cols_to_remove]
```


`r qbegin(15)`
Check parallel analysis and MAP again.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
fa.parallel(df2, fa = 'fa')
```

```{r}
VSS(df2)
```
`r solend()`


`r qbegin(16)`
Fit an 8-factor model to the new dataset.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
m_8f <- fa(df2, nfactors = 8, rotate = "oblimin", fm = "ml")
fa.sort(m_8f)
```

`r solend()`

We still only get 2 substantive loadings on the last factor, while we want at least 3. This also happens with the 7- and 6-factor solutions. But once we hit the 5-factor solution, we find a better structure:


```{r}
m_5f <- fa(df2, nfactors = 5, rotate = "oblimin", fm = "ml")
fa.sort(m_5f)
```



Also notice that the 8-factor solution accounted for 49% of the variance and the 5-factor one explains 41%. That is not a huge drop considering that, by choosing the 5-factor over the 8-factor solution, we reduce the dimensionality of the data (number of variables we have to deal with) by further 3 dimensions!

Looking at the loadings, we can see that only 4 items have substantial cross-loadings (on exactly 2 factors), which is not terrible.

Glance at the factor correlations of this final model, we see that only factor 1 and 4 are weakly-to-moderately correlated, which is not too bad! It allows us to claim that the factors (except for one) are largely independent of each other. This model accounts for about 39% of the common variance.

At this stage, we would go to the individual items, look at which factors load on which items, and try to figure out what is the common theme linking these items. For instance, let’s look at the factor ML5. I would start by looking at the items with the highest loadings, i.e., items 44, 4, 33, and 24. They all have three things in common: they address fairness, openness, and promotions/pay rises. Since we have multiple themes going on here, let’s look at the items with loadings in the .4-.6 range. A stronger theme of fair acknowledgement of performance emerges. Not all of the lower-loading items chime with this theme terribly well, but those that do not tend to have cross-loadings with other factor. I would therefore be reasonable confident that the factor taps into something that could be called "Fair recognition" (apparently this is referred to in the OrgPsych jargon as "Procedural justice").


<!-- Formatting -->

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
